{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration \n",
    "Now that we have the streamflow data imported as a CSV file, we move on to the next step in the analytical workflow, namely exploring the data. After we read the data in CSV file back into our session, we will repeat the exploratory analyses we did in Unit1 with Excel:\n",
    "\n",
    "* Create some scatter plots of the entire dataset as well as for the pre- and post-Falls lake years.\n",
    "\n",
    "\n",
    "* Deriving some new column in our data frame from existing columns:\n",
    " * Create `year` and `month` columns from our `datetime` data\n",
    " * Create a `water_year` column based on year and month values\n",
    " * Convert our *cfs* data into *cms* and *mgd* units and re-plot\n",
    "\n",
    "\n",
    "* Summarize the data by *confidence codes*:\n",
    " * Group the data by data-value qualification (i.e., \"confidence\") codes\n",
    " * Determine how many different codes exist in our data and what those codes are\n",
    " * Compute the number of records in each code\n",
    " * Create a quick bar pot showing the record count in each category\n",
    "\n",
    "\n",
    "* Compute summary statistics of the entire set of discharge data.\n",
    " * Compute min, max, mean, median, as well as specific quantiles.\n",
    " * Plot these values\n",
    " * Repeat for select years of data (pre- and post- Falls Lake construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ♦ Import libraries\n",
    "First, we need to load a few Python packages build for data analyisis projects. We'll grab familiar `pandas`, but also `matplotlib` a widely-used plotting library, and it's companion `seaborn` which facilitates some plotting operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instruct Jupyter to allow plots in the document itself\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ♦ Read the data into a *Pandas* dataframe.\n",
    "Read in the CSV created in the previous notebook into a new Pandas dataframe named `df`. We'll also force the data type of the `site_no` field to be a *string*, not a *number*, which Pandas would infer by default..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved csv file, reading the site_no column as a string, not a number.\n",
    "df = pd.read_csv('GageData.csv', dtype={'site_no':'str'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm it looks good by viewing the first 5 records using the \"head()\" function\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ○ Data types\n",
    "Dataframes are structured so that each column contains values of a constant and defined **data type**. Typical data types in a Pandas dataframe include integers (`int64`), floating point numbers (`float64`), strings (`object`), and date/time objects (`datetime64`).\n",
    "\n",
    "If we import data into a dataframe, it infers data types from the the values in the input file unless we override the defaults, as we did above with the `site_no` varible. We can view the datatypes in a dataframe via the dataframe's `dtypes` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the data types of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `datetime` variable has an incorrectly assigned data type. It is listed as a string (`object`), so we need to re-define it to be a `datetime64` object, specifying the date format our data use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert datetime to an actual datetime object\n",
    "df['datetime'] = pd.to_datetime(df['datetime'],format=('%Y-%m-%d'))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ○ Indexes and data slices\n",
    "Dataframe *indexes* provide different ways to select, sort, and organize data **rows**. By setting our `datetime` field as an index, we can then select rows by date ranges or **\"slices\"**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the date time as the index allows time slicing\n",
    "df.set_index('datetime',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two new dataframe views: One with records before Falls Lake an one after\n",
    "dfPre = df.loc['1930-01-01':'1979-12-31']\n",
    "dfPost = df.loc['1984-01-01':'2017-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Some commands to explore a data slice: uncomment each and run this code block--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfPost.head()\n",
    "#dfPost.shape\n",
    "#dfPost.columns\n",
    "#dfPost['MeanFlow_cfs'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ♦ Deriving new columns \n",
    "We'll want to add a few new columns to our dataset to faciliate analysis. These include:\n",
    "* `MeanFlow_cms` - mean flow, converted from  $ft^3/s$ to $m^3/s$ (1 cfs = 0.028316847 cms)\n",
    "* `MeanFlow_mgd` - mean flow, converted from $ft^3/s$ to $MGal/day$ (1 cfs = 0.6464 mgd)\n",
    "* `year` - The year of the record, extracted from the datetime field\n",
    "* `month` - The month of the record, extracted from the datetime field\n",
    "* `water_year` - The water year of the record which extents from Oct. (of the previous year) thru Sept.\n",
    "\n",
    "And finally, we'll add a column named `status` which will indicate whether the record was collected before construction of Falls Lake (before 1980) or after its completion (after 1984). We could continue to use date slices to compare and plot flow before/after the dam was placed, but creating a new column is more in tune with the \"tidy data\" concept and will facilitate analysis and plots later... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new flow columns: `MeanFlow_cms` and `MeanFlow_mgd`\n",
    "* Converting flow units is relatively easy as we just multiply an entire column by the conversion factor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a column of flow in cubic meters per second\n",
    "df['MeanFlow_cms'] = df['MeanFlow_cfs'] * 0.028316847"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <mark>Now you try it with mgd</mark> `(1 cfs = 0.6464  mgd)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a column of flow in cubic meters per second\n",
    "df['MeanFlow_mgd'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deriving `year` and `month` columns from the `datetime` index\n",
    "* Creating the year and month columns isn't an arithmetic expression, but rather a data type conversion one. The functions `.year` and `.month` on a datetime object extract the year and month, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the year from the datetime index\n",
    "df['year'] = df.index.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <mark>Now see if you can create the `month` column...</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the month from the datetime index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deriving the `water_year` column from the `year` and `month` data. \n",
    "Water year begins in October. Therefore it equals the calendar year for months prior to October, but for October, November, and December, it takes the value of the following year. \n",
    "\n",
    "There are two methods for computing water year. Both yield the exact same results but show different data techniques using Pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ♦ <u>Method 1</u> for computing water year: computing values on filtered records\n",
    "In the first method, we add a new column `water_year` to our data frame, setting its default value to the value in the `year` column. Then we filter for records where the month is >= 10 and revise the value in `water_year` column to be `year + 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column, setting all its values the same as the year column\n",
    "df['water_year'] = df['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mask of just records with months from Jan thru Sept (i.e. < 10)\n",
    "monthMask = df['month'] >= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply this mask to create a view of just records from Jan thru Sept\n",
    "df.loc[monthMask, 'water_year'] = df['year'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have a look at a few random records\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ♦ <u>Method 2</u> for computing water year: using a `lambda` function\n",
    "In this approach, we loop through all records and apply a \"lambda\" function on each. In this lambda function, the value of \"x\" is taken from the `datetime` column and the output of the function is passed into the `water_year2` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a lambda function to assign values to water_year2 based on datetime values\n",
    "df['water_year2'] = df[['year','month']].apply(\n",
    "    lambda row: row['year'] if row['month'] < 10 else row['year'] + 1, \n",
    "    axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the results; water_year and water_year2 are the same...\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the water_year2 column, now that the demonstration is over...\n",
    "df.drop(\"water_year2\",axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deriving the `status` column with values indicating whether the record was recorded before or after Falls Lake construction.\n",
    "Lastly, we'll create our status column with two values: `Before FL` for records before 1980, and `After FL` for records after 1984. We do this by calculating new values on slices of rows, using dates to create the slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign records collected before 1980 a status of \"Before FL\"\n",
    "df.loc['1930-01-01':'1979-12-31','status'] = \"Before FL\"\n",
    "#Assign records collection after 1984 a status of \"After FL\"\n",
    "df.loc['1984-01-01':'2017-12-31','status'] = \"After FL\"\n",
    "#Show a random sample of the dataframe\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ♦ Explore the data: Plotting\n",
    "As we did with Excel, we'd want to explore and examine our data for gaps or outliers. The two approaches for exploring data are to **visualize** the data (e.g. through plots etc.) and to **summarize** our data, both of which might expose odd values or trends in our data.  We'll begin with the former, examining various ways to plot data in Python. Pandas has some plotting capability that will examine. However, we'll also explore the *matplotlib* package, a powerful plotting package that has both Python and R versions, as well as *seaborn* which adds nice aesthetics to our plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple plot using `Pandas` functionality. \n",
    "The Pandas library includes some plotting functionality, making it quite easy to generate a limited number of figures from our data. For more information see <br>https://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
    "\n",
    "* First let's look at the defaul plot, which is a line plot. We specify the value we want to plot, `MeanFlow_cfs`, and without specifying another axis, it uses the index as the independent variable, which in our case is the `datetime` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot using Pandas\n",
    "df['MeanFlow_cfs'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let's look at **box plots**:https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.boxplot.html. <br>First we'll look at a box plot of all the flow data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a box and whiskers plot of our MeanFlow_cms values\n",
    "df.boxplot('MeanFlow_cms');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Now box plots of flow, separated by status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a box and whiskers plot of our MeanFlow_cms values, broken by status\n",
    "df.boxplot('MeanFlow_cms',by='status');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <mark>Now see if you can produce a box plot of flow data by *month*</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <mark>**CHALLENGE**: See if you can produce the above plot, but just for data after 2010</mark><br>Hint: you might want to involve your index..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use *ggplot* to plot\n",
    "An alternative to Pandas built-in plotting capability is [`ggplot`](http://ggplot.yhathq.com/) which is similar, but not idential to R's ggplot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import everything from ggplot\n",
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's bring back our datetime values from index to a column in our dataframe\n",
    "df['datetime'] = df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot using aesthetics\n",
    "ggplot(aes(x='datetime',y='MeanFlow_cfs'), data = df) +\\\n",
    "    geom_line() +\\\n",
    "    xlab(\"Year\")  +\\\n",
    "    ylab(\"Mean Flow (cfs)\") +\\\n",
    "    ggtitle(\"Neuse River near Clayton, NC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a time series plot of mean discharge using `matplotlib`\n",
    "**Matplotlib** has been described as \"the grandfather of plotting\" in Python ([source](http://pbpython.com/visualization-tools-1.html)), borrowing much technique (and syntax) from Matlab. It's not the most friendly, but it does a lot and is worth getting the feel for. \n",
    "\n",
    "We'll go deeper into visualization tools in the next unit, but we'll examine some examples to get the gist. Meanwhile, more documentation can be found here:<br>\n",
    "https://matplotlib.org/devdocs/api/pyplot_summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a plot canvas of a specified size\n",
    "plt.figure(figsize=(20,6));\n",
    "\n",
    "#Plot the mean flow (against time)\n",
    "plt.plot(df['MeanFlow_cfs']);\n",
    "\n",
    "#Add a vertical line indicating when Falls Lake construction began\n",
    "plt.axvline(x='1980-01-01',color='red',ls='--');\n",
    "\n",
    "#Add some aesthetics\n",
    "plt.title(\"Neuse River Near Goldsboro, NC\");\n",
    "plt.ylabel(\"Discharge (cfs)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke `Seaborn` to make prettier plots \n",
    "https://seaborn.pydata.org/tutorial/aesthetics.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activate seaborn default aesthetics\n",
    "sns.set(font_scale=2)\n",
    "#Repeat above\n",
    "plt.figure(figsize=(20,6));\n",
    "plt.plot(df['MeanFlow_cfs']);\n",
    "plt.axvline(x='1980-01-01',color='red',ls='--');\n",
    "plt.title(\"Neuse River Near Goldsboro, NC\");\n",
    "plt.ylabel(\"Discharge (cfs)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a plot of all data, superimposed with the pre- and post-Falls Lake data views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the canvas\n",
    "plt.figure(figsize=(20,6))\n",
    "\n",
    "#Add plot lines for the entire dataframe, then the two dataframe subsets\n",
    "plt.plot(df['MeanFlow_cfs'],color='grey',linewidth=0.1) \n",
    "plt.plot(dfPre['MeanFlow_cfs'],color='green',alpha=0.5,linewidth=0.5)\n",
    "plt.plot(dfPost['MeanFlow_cfs'],color='blue',alpha=0.5,linewidth=0.5)\n",
    "\n",
    "#Add the aesthetics\n",
    "plt.axvline(x='1979-12-31',color='red',ls='--')\n",
    "plt.title(\"Neuse River Near Goldsboro, NC\")\n",
    "plt.ylabel(\"Discharge (cfs)\");\n",
    "plt.annotate('Construction begins',\n",
    "             xy=('1980',16000),\n",
    "             xytext=('1955',18000),\n",
    "             arrowprops=dict(facecolor='red',shrink=0.05))\n",
    "\n",
    "#Show the plot\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting cubic feet/second to cubic *meter*/second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replot (this time in a thinner, orange line)\n",
    "plt.figure(figsize=(20,6));\n",
    "plt.plot(df['datetime'],df['MeanFlow_cms'],linewidth=0.5,color='orange')\n",
    "plt.ylim((0,700))\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <mark> See if you can repeat the plot above, but set the units to `mgd`, make the line `green`, and set the x limit to show just from `1984-01-01` to `2010-01-01`</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replot: modify the commands below..\n",
    "plt.figure(figsize=(20,6));\n",
    "plt.plot(df['datetime'],df['MeanFlow_cms'],linewidth=0.5,color='orange')\n",
    "plt.ylim((0,700))\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ♦ Explore the data: Summarizing\n",
    "The alternative to plotting to explore the data is to summarize. Here we'll examine how to examine properties of our dataset as a whole and also how to group our data and examine summaries by those groupings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we'll examine a few basic properties of our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a count of all records from the dataframe's shape (rows, columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or just show the rows, i.e., the first item in the shape result\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also use the Python `len` command to show the \"lenght\" of the dataframe\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing/grouping records by Confidence code\n",
    "Here, we group the data by the unique values in a column, namely the `Confidence` column. First, we'll just examine the number of unique values and what those values are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use nunique on the column to list the number of unique values\n",
    "print(df['Confidence'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use unique to show what the 4 unique values are\n",
    "print(df['Confidence'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll **group** the records by confidence codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Pandas GroupBy object\n",
    "grpConfidence = df.groupby(['Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now list the counts of records by confidence code\n",
    "grpConfidence.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or we can just show the count by a single column\n",
    "grpConfidence['MeanFlow_cfs'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot counts by confidence code\n",
    "See: https://pandas.pydata.org/pandas-docs/stable/visualization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute counts and plot them as a bar chart\n",
    "count_by_Confidence = grpConfidence['MeanFlow_cfs'].count()\n",
    "count_by_Confidence.plot(kind='pie');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating summary statistics with `Describe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize the MeanFlow_cfs data, using default outputs\n",
    "df['MeanFlow_cms'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize, **using our own percentiles**\n",
    "summary_all = df['MeanFlow_cms'].describe(percentiles=[0.1,0.25,0.75,0.9])\n",
    "summary_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by the status values, and then describe..\n",
    "df.groupby('status')['MeanFlow_cms'].describe(percentiles=[0.1,0.25,0.75,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by the status values, and then describe, and then TRANSPOSE for neater presentation\n",
    "summary_bystatus = df.groupby('status')['MeanFlow_cms'].describe(percentiles=[0.1,0.25,0.75,0.9]).T\n",
    "summary_bystatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate (or join) the pre and post summary objects\n",
    "dfSummary = pd.concat([summary_all, summary_bystatus],axis=1)\n",
    "dfSummary.columns = (\"1930-2017\",\"1930-1980\",\"1984-2017\")\n",
    "dfSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot bar charts of the three summary tables\n",
    "dfSummary[4:9].plot(kind='bar',\n",
    "                    figsize=(20,6),\n",
    "                    title=\"Data Summaries: Quantiles\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly plots\n",
    "To produce monthly plots, we need to group our data by month, then plot. Grouping by month requires us to extract the month from the datetime column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byMonth = df.groupby('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlyDF = byMonth['MeanFlow_cfs'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlyDF.plot(figsize=(20,6),legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>♦Exercise♦: Annual plots</mark>\n",
    " * Add a year column to your dataframe\n",
    " * Group by year\n",
    " * Compute the total (sum) annual discharge\n",
    " * Create a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a year column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute total annual discharge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
