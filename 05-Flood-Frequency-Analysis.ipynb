{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flood frequency analysis\n",
    "Here we apply concepts learned in the previous two notebooks (importing and exploring data) to a specific task, namely computing flood frequency at out gage site. This process involves the following sub-tasks:\n",
    "* Grouping data by water year and computing annual peak flow\n",
    "* Computing return intervals and probability of flood recurrences\n",
    "* Computing a regression between return interval and peak flow\n",
    "* Estimating peak flow from our calculated regression\n",
    "* Plotting our results\n",
    "\n",
    "In doing so, we explore the following Python concepts:\n",
    "* Sorting\n",
    "* Ranking\n",
    "* Grouping/summarizing\n",
    "* Running a regression and projecting results\n",
    "* Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and cleaning data\n",
    "As before, we begin by importing the modules we need, then importing and preparing the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enable inline plots and set to use seaborn styles\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the streamflow data CSV, setting data types on import\n",
    "df=pd.read_csv('GageData.csv',\n",
    "               dtype={'site_no':'str'}, #Set 'site_no' to string obj\n",
    "               parse_dates=['datetime'])#Set 'datetime' as datetime obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add year, month, and water_year columns\n",
    "df['year'] = df['datetime'].map(lambda x: x.year)\n",
    "df['month'] = df['datetime'].map(lambda x: x.month)\n",
    "df['water_year'] = df['datetime'].apply(lambda x: x.year if x.month < 10 else x.year + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute flow in cms\n",
    "df['MeanFlow_cms'] = df['MeanFlow_cfs'] * 0.028316847 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the index to full date\n",
    "df.index = df.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data slices for pre- and post-Falls Lake\n",
    "dfPre = df[:'1980-01-01']\n",
    "dfPost = df['1983-12-31':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute annual peak discharge\n",
    "Compute annual peak flows from our daily flow data. We do this by grouping our data on `water_year` and then computing the max daily discharge for each water year group, the results of which are stored in a new dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Create a dataframe of annual peak flow\n",
    "Annual peak flow is the maximum observed flow in each year, so we need to group values by year and then extract the highest observed flow from each year. The initial result is an array, but we convert it into a dataframe for easier processing afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a \"GroupBy\" object, using water_year as the grouping variable\n",
    "byYear = df.groupby('water_year')\n",
    "#From the GroupBy object, create an array of max values for each water year\n",
    "arrMaxAnnual = byYear['MeanFlow_cms'].max()\n",
    "#Display the first 5 records in the array\n",
    "arrMaxAnnual[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the array to a dataframe, renaming it to PeakFlow_cms\n",
    "dfPF = arrMaxAnnual.to_frame(name=\"PeakFlow_cms\")\n",
    "dfPF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Rank and sort data by max discharge values\n",
    "Compiting return interval (RI) requires our annual data to be ranked on peak discharge. So, before we can compute RI, we need to rank our data. We'll sort them as well, for easier viewing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank discharge from highest to lowest, storing value in a \"rank\" column\n",
    "dfPF['rank'] = dfPF.rank(ascending=False)\n",
    "dfPF.sort_values(by='PeakFlow_cms',ascending=False,inplace=True)\n",
    "dfPF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Compute Return Interval (RI) and Probability of Recurrence (PoR)\n",
    "Recurrence interval is computed for each year by dividing the number of records (plus 1) by the its rank. Probability of recurrence is the inverse of recurrence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the number of records, e.g. the max of all rank values\n",
    "countRecs = dfPF['rank'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ _How else might we determine how many rows are in the table?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Return Interval (RI)\n",
    "dfPF['RI'] = (countRecs + 1) / dfPF['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute probability of recurrence (Pe)\n",
    "dfPF['Pe'] = 1 / dfPF['RI'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results\n",
    "dfPF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "Have a quick look at the data to examine the likelihood of a relationship. Try a few transformations of the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Straight up plot of the data\n",
    "plt.plot(dfPF['RI'],dfPF['PeakFlow_cms'],'o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log transform the x-axis\n",
    "plt.plot(dfPF['RI'],dfPF['PeakFlow_cms'],'o')\n",
    "plt.xscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute a regression using SciPy functions\n",
    "SciPy's [`linregress`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html) function allows us to calculate linear regressions for two sets of measurements. It returns an array of 5 objects: the slope, intercept, r-value, p-value, and std. error of the model. We can use this function to quickly evaluate different transformation of our data to get the best fit trend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple linear regression\n",
    "x = dfPF['RI']\n",
    "y = dfPF['PeakFlow_cms']\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "print (r_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression, with log-transformed X\n",
    "x = np.log(dfPF['RI'])\n",
    "y = dfPF['PeakFlow_cms']\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "print (\"y = {0:0.2f}*ln(x) + {1:0.2f}; r2 = {2:0.2f}\".format(slope, intercept, r_value**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the equation to 100, 500, and 1000 year return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an array of years\n",
    "arrYears = pd.Series([100,500,1000])\n",
    "arrYears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the regression equations to these values\n",
    "arrFlood = slope * np.log(arrYears) + intercept\n",
    "arrFlood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to a dataframe\n",
    "dfFlood = pd.concat([arrYears,arrFlood],axis=1)\n",
    "dfFlood.columns = ('RI','PeakFlow_cms')\n",
    "dfFlood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the R value for the log transformed is much better than the non-transformed model. Let's proceed with that. First we'll plot the data and then we'll add some additional points to our plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A quick plot with a trendline computed from the data\n",
    "plt.plot(x,y,'o',label='original data')\n",
    "plt.plot(x,slope * x + intercept,'r--',label='fitted line')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like above, but with an extended trendline and projected data\n",
    "plt.plot(x,y,'o',alpha=0.5,label='original data')\n",
    "plt.plot(np.log(dfFlood['RI']),dfFlood['PeakFlow_cms'],'or',label='projected data')\n",
    "\n",
    "x1 = np.linspace(1,1000,50) #An array of 100 equal spaced values from 0 to 1000\n",
    "lnX1 = np.log(x1)           #Log transform the vaues\n",
    "plt.plot(lnX1,slope * lnX1 + intercept,'g--',label='fitted line')\n",
    "\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fancier plotting\n",
    "https://seaborn.pydata.org/tutorial/regression.html\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.regplot.html#seaborn.regplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the canvas (fig) and axes (ax) objects, setting the figure size\n",
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "\n",
    "#Set axis properties\n",
    "ax.set(xlim=(1,1200),\n",
    "       ylim=(0,1200),\n",
    "       xscale =\"log\",\n",
    "       label=\"y = ({0:0.2f}ln(x)+{1:0.2f}\".format(slope,intercept)\n",
    "      )\n",
    "\n",
    "#Add the seaborn regression plot to our figure\n",
    "ax = sns.regplot(x='RI',\n",
    "                 y='PeakFlow_cms',\n",
    "                 data=dfPF,\n",
    "                 logx=True,\n",
    "                 fit_reg=True,\n",
    "                 ci=None,\n",
    "                )\n",
    "\n",
    "#Set the axis labels.\n",
    "ax.set(xlabel='ln(Return Interval (years))', \n",
    "       ylabel='Peak discharge(cms)',\n",
    "       title=\"Flood Frequency: All Years\"\n",
    "      )\n",
    "\n",
    "ax.text(2,500,\"y = {0:.1f}ln(x)+{1:.1f}; r={2:.2f}\".format(slope,intercept,r_value))\n",
    "\n",
    "ax = sns.regplot(x='RI',\n",
    "                 y='PeakFlow_cms',\n",
    "                 data=dfFlood,\n",
    "                 logx=True,\n",
    "                 fit_reg=False,\n",
    "                 ci=None,\n",
    "                 color=\"red\",\n",
    "                 marker='o'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ♦ Exercise: Calculate the return interval from the pre-1980 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy peak flow data before 1980 to a new dataframe\n",
    "dfPFPre = dfPF.loc[dfPF.index < 1980].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-rank the data\n",
    "dfPFPre['rank'] = dfPFPre.rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-compute RI & Pe\n",
    "countRecs = dfPFPre['rank'].max()\n",
    "dfPFPre['RI'] = (countRecs + 1) / dfPFPre['rank']\n",
    "dfPFPre['Pe'] = 1/dfPFPre['RI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-compute the regression\n",
    "x = np.log(dfPFPre['RI'])\n",
    "y = dfPFPre['PeakFlow_cms']\n",
    "slope1, intercept1, r_value1, p_value1, std_err1 = stats.linregress(x, y)\n",
    "print(\"y = {0:0.1f}ln(x) + {1:0.1f}; r2={2:0.2f}\".format(slope1,intercept1,r_value1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute 100, 500, and 1000 year floods; adding to previous dfFlood dataframe\n",
    "dfFlood['PreLake_cms'] = slope1 * np.log(dfFlood['RI']) + intercept1\n",
    "dfFlood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(x,y,'o',alpha=0.5,label='original data')\n",
    "plt.plot(np.log(dfFlood['RI']),dfFlood['PreLake_cms'],'or',label='projected data')\n",
    "\n",
    "x1 = np.linspace(1,1000,50) #An array of 100 equal spaced values from 0 to 1000\n",
    "lnX1 = np.log(x1)           #Log transform the vaues\n",
    "plt.plot(lnX1,slope * lnX1 + intercept,'g--',label='fitted line')\n",
    "plt.plot(lnX1,slope1 * lnX1 + intercept1,'k--',label='Pre1980',linewidth=1,alpha=0.9)\n",
    "\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
