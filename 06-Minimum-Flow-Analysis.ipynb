{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating impact on minimum flows\n",
    "## Background & Framing the Analysis: 7Q10\n",
    "\n",
    "The passing of the Clean Water Act in 1972 and the Endangered Species Act in 1973 has resulted in many reservoirs having to meet downstream flow requirements for either water quality purposes or species protection. For example, at the Clayton gauge, minimum flow requirements have ranged from 184 to 404 cfs since 1983. Here we want to see if Falls Lake has raised minimum flows.\n",
    "\n",
    "There are many ways to approach low flow to understand how minimum streamflow has changed since Falls Lake was constructed. We will look at a common metric known as 7Q10. 7Q10 is the lowest average discharge over a one [week/month/year] period with a recurrence interval of 10 years. This means there is only a 10% probability that there will be lower flows than the 7Q10 threshold in any given year.\n",
    "\n",
    "To get more practice with pivot tables and if statements, we will calculate this metric using the 7 month period. To do this we need to construct a rolling average of monthly discharges spanning 7 month, which we can do using a series of pivot tables.\n",
    "\n",
    "The first pivot table aggregates our daily discharge data into total monthly discharge values for each year. From this we table, we can compute a 7-month rolling average of minimum-flows from the given monthâ€™s total discharge and those from 6 months preceding it.\n",
    "\n",
    "Next, we construct a second Pivot Table from the above data. This one aggregates the monthly data by year, extracting the minimum of the 7-month average for each year. This will enable us to compute a regression similar the one we constructed for the flood return interval, but this regression is to reveal the recurrence interval of low flows so that we can determine the streamflow of a 10% low flow event.\n",
    "\n",
    "We then sort and rank these annual monthly-minimum values, similar to how we computed flood return intervals to compute 7 month minimum-flow (7Q) return interval and then the low flow probability of recurrence (POR) of these flows, again using the same methods used for calculating flood return intervals and probabilities of recurrence. From this we can compute a regression between our yearly 7Q flows and POR, and use that regression equation to determine 7Q10, or the expected minimum flow across a span of 10 years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the workspace by importing packages and setting up defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some new modules for computing linear regressions\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import scale\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enable inline plots\n",
    "%matplotlib inline\n",
    "#Set default figure sizes\n",
    "rcParams['figure.figsize'] = 20,6\n",
    "#Set the seaborn style and font scale\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data from the `csv` file and add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the streamflow data CSV and format columns\n",
    "df=pd.read_csv('GageData.csv',dtype={'site_no':'str'},parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add year, month, and water_year columns\n",
    "df['year'] = df['datetime'].map(lambda x: x.year)\n",
    "df['month'] = df['datetime'].map(lambda x: x.month)\n",
    "df['water_year'] = df['datetime'].apply(lambda x: x.year if x.month >= 10 else x.year - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute flow in cms\n",
    "df['MeanFlow_cms'] = df['MeanFlow_cfs'] * 0.028316847 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the index to full date\n",
    "df.index = df.datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by month and year, computing total discharge for all days in each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group data on year and month\n",
    "groupObj = df.groupby(('year','month'))\n",
    "sMonthlyFlow = groupObj['MeanFlow_cms'].sum()\n",
    "#Convert series to dataframe\n",
    "dfMonthlyFlow = sMonthlyFlow.to_frame()\n",
    "dfMonthlyFlow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the 7-month rolling average of monthly stream flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute 7 month rolling average\n",
    "dfMonthlyFlow['7Q'] = dfMonthlyFlow.rolling(window=7,min_periods=7).mean()\n",
    "dfMonthlyFlow.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute min of 7Q for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLowFlow = dfMonthlyFlow.groupby('year')['7Q'].min().to_frame()\n",
    "#Drop null records\n",
    "dfLowFlow.dropna(inplace=True)\n",
    "\n",
    "dfLowFlow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute return interval (RI) and probability of recurrence (POR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute rankings\n",
    "dfLowFlow['rank'] = dfLowFlow.rank(ascending=True)\n",
    "dfLowFlow.sort_values(by='7Q',ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Return Interval (RI)\n",
    "countRecs = dfLowFlow['rank'].max()\n",
    "dfLowFlow['RI'] = (countRecs + 1) / dfLowFlow['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute probability of recurrence (POR)\n",
    "dfLowFlow['POR'] = 1 / dfLowFlow['RI'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLowFlow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the [exponential] regression using NumPy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the X and Y variables\n",
    "x = dfLowFlow['POR']\n",
    "y = dfLowFlow['7Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the slope and intercept using the polyfit function\n",
    "# -> Use the *log of POR* to mimic an exponential relation\n",
    "#    http://bit.ly/2FOLJk2\n",
    "regSlope, ln_regIntercept = np.polyfit(x, np.log(y), 1)\n",
    "\n",
    "# Compute the true intercept from the ln_intercept\n",
    "regIntercept = np.exp(ln_regIntercept)\n",
    "\n",
    "# Create a printer friendly equation\n",
    "regText = \"y = {0:.2f} * e^({1:.2f}x)\".format(regIntercept,regSlope)\n",
    "print(regText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the regression to compute 7Q10 (min flow at a 10% POR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10 = regIntercept * np.exp(regSlope * 0.10)\n",
    "print(q10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a trendline dataset using the exponential formula\n",
    "Seaborn/Matplotlib's trendline represents a linear function, so to add a trendline for another relationship (e.g. exponential) we need to construct it ourselves. We do this by generating an array of equally spaced X values (using NumPy's `linspace` function), and then compute the corresponding Y values by applying the function derived above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the array of 100 X value spanning from the min and max POR values\n",
    "arrX = np.linspace(x.min(),x.max(),100)\n",
    "\n",
    "#Compute the corresponding Y's\n",
    "arrY = regIntercept * np.exp(regSlope*arrX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the blank figure\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "#Add axes to the figure\n",
    "ax = fig.add_axes([.1, .1, 1, 1])\n",
    "\n",
    "#--Generate plot\n",
    "#Plot the data\n",
    "ax = sns.regplot(x='POR',\n",
    "                 y='7Q',\n",
    "                 data=dfLowFlow,\n",
    "                 logx=False,\n",
    "                 fit_reg=False,\n",
    "                 ci=None)\n",
    "\n",
    "\n",
    "#--Specify plot and layout parameters\n",
    "\n",
    "#Set bounds of plot\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0,1400)\n",
    "\n",
    "#Set title and axis labels\n",
    "ax.set_title('7Q10 Monthly Probability')\n",
    "ax.set_xlabel('Probability of smaller flows')\n",
    "ax.set_ylabel('7Q10 Montly Discharge (cms)')\n",
    "\n",
    "#Add an annotation of the formula\n",
    "ax.text(0.82,570, regText)\n",
    "\n",
    "#---Add 7Q10 and the trendline\n",
    "#Add the 7Q10 (computed earler as 'q10') as a large black circle\n",
    "ax = plt.plot(0.10,q10,'ok',markersize=15)\n",
    "\n",
    "#Add the trendline data\n",
    "ax = plt.plot(arrX,arrY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many months had flows under 7Q10?\n",
    "Here we filter our table of Monthly total discharge to identify records where discharge fell below the 7Q10 threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to 'flatten' our multi-level index into one object\n",
    "dfFlow = dfMonthlyFlow.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count low flows per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a view of the records where MeanFlow fell below the computed q10\n",
    "dfLowFlowRecs = dfFlow[dfFlow['MeanFlow_cms'] < q10]\n",
    "print(\"{} months fell below 7Q10\".format(len(dfLowFlowRecs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the flows, indicicating which months fell below 7Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, plot all lines\n",
    "plt.plot(dfFlow['MeanFlow_cms'],'--')\n",
    "#Plot all points\n",
    "plt.plot(dfFlow['MeanFlow_cms'],'bo',markersize=6)\n",
    "#Plot all low flow points\n",
    "plt.plot(dfLowFlowRecs['MeanFlow_cms'],'ro',markersize=6);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
